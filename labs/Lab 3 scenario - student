{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab 3 scenario - student","provenance":[{"file_id":"1mbRybTuEd5hfMgPq47jAy40aizNX03x8","timestamp":1636489869636},{"file_id":"1hs2ViNkY7vFE7l_PL7b-2XIN17cxbsyL","timestamp":1635823858600},{"file_id":"1t76la2tUWVLnEK7IKxdFZn_Y0be3xZud","timestamp":1635823610862}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f6c4fb46b63c4f18831e685a5ffef26e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_02d620d3005a4306a62b71f5a7d5c1c1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a76b23c22d694e6089994d269ae779c2","IPY_MODEL_0c252b8e627c481fb2bd51b28abfd28e","IPY_MODEL_088fffebfeea4ce7a61ef00ef5a2d35e"]}},"02d620d3005a4306a62b71f5a7d5c1c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a76b23c22d694e6089994d269ae779c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_844419ff473d4e27bd16f1e804bbab25","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b258a5eea15945028c6e52c65c5423bf"}},"0c252b8e627c481fb2bd51b28abfd28e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_13b5af5c8f1a495d94f7985e25a35011","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":9912422,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9912422,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_79c39dff277b4300912961bef64b994e"}},"088fffebfeea4ce7a61ef00ef5a2d35e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_611ca170e06f43eb81ad3763caeb1e04","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9913344/? [00:00&lt;00:00, 48641238.52it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_15d3d49c63b84079b22a427d2f7bdd6c"}},"844419ff473d4e27bd16f1e804bbab25":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b258a5eea15945028c6e52c65c5423bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"13b5af5c8f1a495d94f7985e25a35011":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"79c39dff277b4300912961bef64b994e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"611ca170e06f43eb81ad3763caeb1e04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"15d3d49c63b84079b22a427d2f7bdd6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e66e564941144d4ba6df8b2bd6483954":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ced5852f8bc34553aefa9cc653adb4fa","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f5424f2414a342e2aad403b4c427445c","IPY_MODEL_f2e0d944b4b84792901356dbc83925c6","IPY_MODEL_83c53e704c0e41f0a57067137f18aad4"]}},"ced5852f8bc34553aefa9cc653adb4fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f5424f2414a342e2aad403b4c427445c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6280d404021b4b97bb7a553b3b615a5c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c911118915384d04bfabf5d379fcc75f"}},"f2e0d944b4b84792901356dbc83925c6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a7e7d96c46ce4632a11a6ae9c232cd0e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":28881,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28881,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2e4e79a4da1a4c849590b8756d2e8e7b"}},"83c53e704c0e41f0a57067137f18aad4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_66f082368e9b41079ee94d15c4adbae1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29696/? [00:00&lt;00:00, 603643.80it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_46b7979ac00e4f6cae82f748fd2c42ff"}},"6280d404021b4b97bb7a553b3b615a5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c911118915384d04bfabf5d379fcc75f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a7e7d96c46ce4632a11a6ae9c232cd0e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2e4e79a4da1a4c849590b8756d2e8e7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"66f082368e9b41079ee94d15c4adbae1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"46b7979ac00e4f6cae82f748fd2c42ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fcc8ff49d7e247619a755f16e3634f98":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_09fd7c8c59ff4ddeb81063f3955293d8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6597354d28e34968916fb0d0d28bf719","IPY_MODEL_d39ce0ec90fe4a68ac81a826bf98fa5a","IPY_MODEL_66480e5fc8b14bc6a803fd29ff7f98e6"]}},"09fd7c8c59ff4ddeb81063f3955293d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6597354d28e34968916fb0d0d28bf719":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d399772c871d48b1a9a695b6c28553e4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9720baeafc794d1ea68fe10a830ac867"}},"d39ce0ec90fe4a68ac81a826bf98fa5a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6d3419de37084cff810f60b74661a888","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1648877,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1648877,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_366bfbca05bb46989071e1b2c11213a1"}},"66480e5fc8b14bc6a803fd29ff7f98e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_31800d7a7b614f2fbd92491ad2ff9813","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1649664/? [00:00&lt;00:00, 17260999.09it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fdc3c64b5bf14a37a3efbd1367824aa7"}},"d399772c871d48b1a9a695b6c28553e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9720baeafc794d1ea68fe10a830ac867":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6d3419de37084cff810f60b74661a888":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"366bfbca05bb46989071e1b2c11213a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"31800d7a7b614f2fbd92491ad2ff9813":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fdc3c64b5bf14a37a3efbd1367824aa7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ec40a24408684333929d67f3c0e92903":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_edf67003270d4ed0b424c9dea792e3fb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bb8c6ba057ef424b88472ae9caabaa4c","IPY_MODEL_39db7f9dd41f414ab1ecba1d79652b9d","IPY_MODEL_791fa41c11ba4b4e83925a9a7dc68c71"]}},"edf67003270d4ed0b424c9dea792e3fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bb8c6ba057ef424b88472ae9caabaa4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d3c14198f33944cf90fb4be52fdae948","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1d4d4e9a5bd34fd5a7591f0cb52696e4"}},"39db7f9dd41f414ab1ecba1d79652b9d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_dfc8f3176af4448e97a02f20a42aa055","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":4542,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4542,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_74db097132e94b4da68bdf0ab37e08de"}},"791fa41c11ba4b4e83925a9a7dc68c71":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_92a1e7fcfffe467c9388d1beddb64cf7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5120/? [00:00&lt;00:00, 153243.92it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_765353a29b864280904a31ee147ba73d"}},"d3c14198f33944cf90fb4be52fdae948":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1d4d4e9a5bd34fd5a7591f0cb52696e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dfc8f3176af4448e97a02f20a42aa055":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"74db097132e94b4da68bdf0ab37e08de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"92a1e7fcfffe467c9388d1beddb64cf7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"765353a29b864280904a31ee147ba73d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"ziZ9i7tXbO1T"},"source":["In this lab, you will implement some of the techniques discussed in the lecture.\n","\n","Below you are given a solution to the previous scenario. Note that it has two serious drawbacks:\n"," * The output predictions do not sum up to one (i.e. it does not return a distribution) even though the images always contain exactly one digit.\n"," * It uses MSE coupled with output sigmoid which can lead to saturation and slow convergence \n","\n","**Task 1.** Use softmax instead of coordinate-wise sigmoid and use log-loss instead of MSE. Test to see if this improves convergence. Hint: When implementing backprop it might be easier to consider these two function as a single block and not even compute the gradient over the softmax values. \n","\n","**Task 2.** Implement L2 regularization and add momentum to the SGD algorithm. Play with different amounts of regularization and momentum. See if this improves accuracy/convergence.\n","\n","**Task 3 (optional).** Implement Adagrad, dropout and some simple data augmentations (e.g. tiny rotations/shifts etc.). Again, test to see how these changes improve accuracy/convergence.\n","\n","**Task 4.** Try adding extra layers to the network. Again, test how the changes you introduced affect accuracy/convergence. As a start, you can try this architecture: [784,100,30,10]\n"]},{"cell_type":"code","metadata":{"id":"N9jGPaZhbO2B","colab":{"base_uri":"https://localhost:8080/","height":423,"referenced_widgets":["f6c4fb46b63c4f18831e685a5ffef26e","02d620d3005a4306a62b71f5a7d5c1c1","a76b23c22d694e6089994d269ae779c2","0c252b8e627c481fb2bd51b28abfd28e","088fffebfeea4ce7a61ef00ef5a2d35e","844419ff473d4e27bd16f1e804bbab25","b258a5eea15945028c6e52c65c5423bf","13b5af5c8f1a495d94f7985e25a35011","79c39dff277b4300912961bef64b994e","611ca170e06f43eb81ad3763caeb1e04","15d3d49c63b84079b22a427d2f7bdd6c","e66e564941144d4ba6df8b2bd6483954","ced5852f8bc34553aefa9cc653adb4fa","f5424f2414a342e2aad403b4c427445c","f2e0d944b4b84792901356dbc83925c6","83c53e704c0e41f0a57067137f18aad4","6280d404021b4b97bb7a553b3b615a5c","c911118915384d04bfabf5d379fcc75f","a7e7d96c46ce4632a11a6ae9c232cd0e","2e4e79a4da1a4c849590b8756d2e8e7b","66f082368e9b41079ee94d15c4adbae1","46b7979ac00e4f6cae82f748fd2c42ff","fcc8ff49d7e247619a755f16e3634f98","09fd7c8c59ff4ddeb81063f3955293d8","6597354d28e34968916fb0d0d28bf719","d39ce0ec90fe4a68ac81a826bf98fa5a","66480e5fc8b14bc6a803fd29ff7f98e6","d399772c871d48b1a9a695b6c28553e4","9720baeafc794d1ea68fe10a830ac867","6d3419de37084cff810f60b74661a888","366bfbca05bb46989071e1b2c11213a1","31800d7a7b614f2fbd92491ad2ff9813","fdc3c64b5bf14a37a3efbd1367824aa7","ec40a24408684333929d67f3c0e92903","edf67003270d4ed0b424c9dea792e3fb","bb8c6ba057ef424b88472ae9caabaa4c","39db7f9dd41f414ab1ecba1d79652b9d","791fa41c11ba4b4e83925a9a7dc68c71","d3c14198f33944cf90fb4be52fdae948","1d4d4e9a5bd34fd5a7591f0cb52696e4","dfc8f3176af4448e97a02f20a42aa055","74db097132e94b4da68bdf0ab37e08de","92a1e7fcfffe467c9388d1beddb64cf7","765353a29b864280904a31ee147ba73d"]},"executionInfo":{"status":"ok","timestamp":1638977837396,"user_tz":-60,"elapsed":7341,"user":{"displayName":"Bartłomiej Krzepkowski","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14471650214675903305"}},"outputId":"bbc6ee6c-8010-40e0-bd70-088814d19d93"},"source":["import random\n","import numpy as np\n","from torchvision import datasets, transforms\n","\n","# Let's read the mnist dataset\n","\n","def load_mnist(path='.'):\n","    train_set = datasets.MNIST(path, train=True, download=True)\n","    x_train = train_set.data.numpy()\n","    _y_train = train_set.targets.numpy()\n","    \n","    test_set = datasets.MNIST(path, train=False, download=True)\n","    x_test = test_set.data.numpy()\n","    _y_test = test_set.targets.numpy()\n","    \n","    x_train = x_train.reshape((x_train.shape[0],28*28)) / 255.\n","    x_test = x_test.reshape((x_test.shape[0],28*28)) / 255.\n","\n","    y_train = np.zeros((_y_train.shape[0], 10))\n","    y_train[np.arange(_y_train.shape[0]), _y_train] = 1\n","    \n","    y_test = np.zeros((_y_test.shape[0], 10))\n","    y_test[np.arange(_y_test.shape[0]), _y_test] = 1\n","\n","    # mean = x_train.mean()\n","    # std = x_train.std()\n","\n","    # x_train = (x_train - mean) / std\n","    # x_test = (x_test - mean) / std\n","\n","    return (x_train, y_train), (x_test, y_test)\n","\n","(x_train, y_train), (x_test, y_test) = load_mnist()"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f6c4fb46b63c4f18831e685a5ffef26e","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/9912422 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e66e564941144d4ba6df8b2bd6483954","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/28881 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fcc8ff49d7e247619a755f16e3634f98","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1648877 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec40a24408684333929d67f3c0e92903","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/4542 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n","\n"]}]},{"cell_type":"code","metadata":{"id":"w3gAyqw4bO1p","executionInfo":{"status":"ok","timestamp":1638977842253,"user_tz":-60,"elapsed":1,"user":{"displayName":"Bartłomiej Krzepkowski","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14471650214675903305"}}},"source":["clip = 500\n","def sigmoid(z):\n","  z = np.clip(z, -clip, clip)\n","  return 1.0 / (1.0 + np.exp(-z))\n","\n","def softmax(x):\n","  max_x = np.max(x, axis=0)[np.newaxis,:]\n","  exp_x = np.exp(x-max_x)\n","  return exp_x / exp_x.sum(axis=0)[np.newaxis,:]\n","\n","def relu(x):\n","  return np.maximum(x,0)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_DYlA8QIqAUB"},"source":["Abstract Class"]},{"cell_type":"code","metadata":{"id":"HBtZB0g3qFIa","executionInfo":{"status":"ok","timestamp":1638977844672,"user_tz":-60,"elapsed":1038,"user":{"displayName":"Bartłomiej Krzepkowski","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14471650214675903305"}}},"source":["class Network_(object):\n","    def __init__(self, sizes, act_name):\n","        # initialize biases and weights with random normal distr.\n","        # weights are indexed by target node first\n","        self.num_layers = len(sizes)\n","        self.sizes = sizes\n","        self.biases = [np.zeros((y, 1)) for y in sizes[1:]]\n","        self.weights = [np.random.normal(0, np.sqrt(6/(x+y)), (y, x)) \n","                        for x, y in zip(sizes[:-1], sizes[1:])]\n","        self.act_name = act_name\n","\n","    def feedforward(self, a):\n","        # Run the network on a batch\n","        for w,b in zip(self.weights[:-1], self.biases[:-1]):\n","          h = np.dot(w, a) + b\n","          a = relu(h) if self.act_name == 'relu' else sigmoid(h)\n","        h = np.dot(self.weights[-1], a) + self.biases[-1]\n","        return h\n","    \n","    def update_mini_batch(self, x_batch, y_batch, eta):\n","        # Update networks weights and biases by applying a single step\n","        # of gradient descent using backpropagation to compute the gradient.\n","        # The gradient is computed for a mini_batch.\n","        # eta is the learning rate\n","        nabla_b, nabla_w = self.backprop(x_batch.T, y_batch.T)\n","        self.weights = [w-(eta/len(x_batch))*nw \n","                        for w, nw in zip(self.weights, nabla_w)]\n","        self.biases = [b-(eta/len(x_batch))*nb \n","                       for b, nb in zip(self.biases, nabla_b)]\n","\n","    def backprop(self, x_batch, y_batch):\n","        # For a single input (x,y) return a tuple of lists.\n","        # First contains gradients over biases, second over weights.\n","        \n","        fs = [x_batch]\n","        deriv_fs = []\n","        for w,b in zip(self.weights[:-1], self.biases[:-1]):\n","          h = w @ fs[-1] + b\n","          f = relu(h) if self.act_name == 'relu' else sigmoid(h)\n","          fs.append(f)\n","          deriv_fs.append((h>0).astype(int) \\\n","                          if self.act_name == 'relu' else f*(1-f))\n","\n","        h = np.dot(self.weights[-1], f) + self.biases[-1]\n","        # Now go backward from the final cost applying backpropagation\n","        # dLdf = dLdh\n","        dLdh = self.cost_derivative(h, y_batch)\n","        dLdhs = [dLdh.copy()]\n","        for w, deriv_f in reversed(list(zip(self.weights[1:],deriv_fs))):\n","          dLdf = w.T @ dLdh\n","          dLdh = dLdf * deriv_f\n","          dLdhs.append(dLdh)\n","          \n","        delta_nabla_w = [dLdh @ f.T for dLdh, f in zip(reversed(dLdhs),fs)] \n","        delta_nabla_b = [dLdh.sum(axis=1)[:, np.newaxis] \n","                         for dLdh in reversed(dLdhs)]\n","\n","        return (delta_nabla_b, delta_nabla_w)\n","\n","    def evaluate(self, test_data):\n","        # Count the number of correct answers for test_data\n","        pred = np.argmax(self.feedforward(test_data[0].T),axis=0)\n","        corr = np.argmax(test_data[1],axis=1).T\n","        return np.mean(pred==corr)\n","    \n","    def cost_derivative(self, output_activations, y):\n","        return (softmax(output_activations)-y) \n","    \n","    def SGD(self, training_data, epochs, mini_batch_size, eta, test_data=None, p=0.1, step=10):\n","        x_train, y_train = training_data\n","        data_size = y_train.shape[0]\n","        if test_data:\n","            x_test, y_test = test_data\n","        for j in range(epochs):\n","            idx = np.random.permutation(data_size)\n","            x_train = x_train[idx]\n","            y_train = y_train[idx]\n","            for i in range(data_size // mini_batch_size):\n","                x_mini_batch = x_train[(mini_batch_size*i):(mini_batch_size*(i+1))]\n","                y_mini_batch = y_train[(mini_batch_size*i):(mini_batch_size*(i+1))]\n","                self.update_mini_batch(x_mini_batch, y_mini_batch, eta)\n","            if j % step == 0:\n","                if test_data:\n","                    print(\"Epoch: {0}, Accuracy: {1}\".format(j, self.evaluate((x_test, y_test))))\n","                else:\n","                    print(\"Epoch: {0}\".format(j))\n","\n"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-kt5oqT83WLu"},"source":["Baseline:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nSKWRMa6q4IN","executionInfo":{"status":"ok","timestamp":1638835635375,"user_tz":-60,"elapsed":90153,"user":{"displayName":"Bartłomiej Krzepkowski","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14471650214675903305"}},"outputId":"d1f03b33-fbfb-446d-9190-9e93eb985ff7"},"source":["class Network(Network_):\n","  def __init__(self, sizes, act_name):\n","    super(Network, self).__init__(sizes, act_name)\n","\n","  def update_mini_batch(self, x_batch, y_batch, eta):\n","        # Update networks weights and biases by applying a single step\n","        # of gradient descent using backpropagation to compute the gradient.\n","        # The gradient is computed for a mini_batch.\n","        # eta is the learning rate\n","        nabla_b, nabla_w = self.backprop(x_batch.T, y_batch.T)\n","        self.weights = [w-(eta/len(x_batch))*nw \n","                        for w, nw in zip(self.weights, nabla_w)]\n","        self.biases = [b-(eta/len(x_batch))*nb \n","                       for b, nb in zip(self.biases, nabla_b)]\n","\n","network1 = Network([784,100,30,10], act_name='relu')\n","network1.SGD((x_train, y_train), epochs=50, mini_batch_size=100, eta=0.05,\n","            test_data=(x_test, y_test), step=2)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Accuracy: 0.923\n","Epoch: 2, Accuracy: 0.9529\n","Epoch: 4, Accuracy: 0.9584\n","Epoch: 6, Accuracy: 0.9671\n","Epoch: 8, Accuracy: 0.9682\n","Epoch: 10, Accuracy: 0.9699\n","Epoch: 12, Accuracy: 0.9707\n","Epoch: 14, Accuracy: 0.9704\n","Epoch: 16, Accuracy: 0.9722\n","Epoch: 18, Accuracy: 0.9726\n","Epoch: 20, Accuracy: 0.9737\n","Epoch: 22, Accuracy: 0.9736\n","Epoch: 24, Accuracy: 0.9743\n","Epoch: 26, Accuracy: 0.9747\n","Epoch: 28, Accuracy: 0.9755\n","Epoch: 30, Accuracy: 0.975\n","Epoch: 32, Accuracy: 0.9753\n","Epoch: 34, Accuracy: 0.9745\n","Epoch: 36, Accuracy: 0.9744\n","Epoch: 38, Accuracy: 0.9758\n","Epoch: 40, Accuracy: 0.975\n","Epoch: 42, Accuracy: 0.9751\n","Epoch: 44, Accuracy: 0.974\n","Epoch: 46, Accuracy: 0.9747\n","Epoch: 48, Accuracy: 0.9743\n"]}]},{"cell_type":"markdown","metadata":{"id":"XjjEWqzDC4MG"},"source":["Gradient Noise"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":607},"id":"iNiuAzWWC6wx","executionInfo":{"status":"error","timestamp":1638835817516,"user_tz":-60,"elapsed":146740,"user":{"displayName":"Bartłomiej Krzepkowski","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14471650214675903305"}},"outputId":"81acccaa-5bb4-4268-cb1d-d304f07f20cb"},"source":["class Network_GN(Network_):\n","  def __init__(self, sizes, act_name, gamma=10):\n","    super(Network_GN, self).__init__(sizes, act_name)\n","    self.step = 0\n","    self.gamma = gamma\n","\n","  def update_mini_batch(self, x_batch, y_batch, eta):\n","        # Update networks weights and biases by applying a single step\n","        # of gradient descent using backpropagation to compute the gradient.\n","        # The gradient is computed for a mini_batch.\n","        # eta is the learning rate\n","        nabla_b, nabla_w = self.backprop(x_batch.T, y_batch.T)\n","        self.sigma2 = eta / (1+self.step)**self.gamma\n","        self.weights = [w-eta*(nw /len(x_batch) + np.random.normal(0, self.sigma2, size=nw.shape))\n","                        for w, nw in zip(self.weights, nabla_w)]\n","        self.biases = [b-eta*(nb /len(x_batch) + np.random.normal(0, self.sigma2, size=nb.shape))\n","                       for b, nb in zip(self.biases, nabla_b)]\n","        self.step += 1\n","\n","network1 = Network_GN([784,100,30,10], act_name='relu')\n","network1.SGD((x_train, y_train), epochs=50, mini_batch_size=100, eta=0.05,\n","            test_data=(x_test, y_test), step=2)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Accuracy: 0.9287\n","Epoch: 2, Accuracy: 0.9527\n","Epoch: 4, Accuracy: 0.9645\n","Epoch: 6, Accuracy: 0.9659\n","Epoch: 8, Accuracy: 0.9685\n","Epoch: 10, Accuracy: 0.968\n","Epoch: 12, Accuracy: 0.9713\n","Epoch: 14, Accuracy: 0.9718\n","Epoch: 16, Accuracy: 0.9718\n","Epoch: 18, Accuracy: 0.975\n","Epoch: 20, Accuracy: 0.9746\n","Epoch: 22, Accuracy: 0.974\n","Epoch: 24, Accuracy: 0.9746\n","Epoch: 26, Accuracy: 0.9751\n","Epoch: 28, Accuracy: 0.9759\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-e717f75c0db8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mnetwork1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork_GN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m network1.SGD((x_train, y_train), epochs=50, mini_batch_size=100, eta=0.05,\n\u001b[0;32m---> 22\u001b[0;31m             test_data=(x_test, y_test), step=2)\n\u001b[0m","\u001b[0;32m<ipython-input-4-335264b81c49>\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(self, training_data, epochs, mini_batch_size, eta, test_data, p, step)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mx_mini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0my_mini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_mini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-e717f75c0db8>\u001b[0m in \u001b[0;36mupdate_mini_batch\u001b[0;34m(self, x_batch, y_batch, eta)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         self.weights = [w-eta*(nw /len(x_batch) + np.random.normal(0, self.sigma2, size=nw.shape))\n\u001b[0;32m---> 15\u001b[0;31m                         for w, nw in zip(self.weights, nabla_w)]\n\u001b[0m\u001b[1;32m     16\u001b[0m         self.biases = [b-eta*(nb /len(x_batch) + np.random.normal(0, self.sigma2, size=nb.shape))\n\u001b[1;32m     17\u001b[0m                        for b, nb in zip(self.biases, nabla_b)]\n","\u001b[0;32m<ipython-input-6-e717f75c0db8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         self.weights = [w-eta*(nw /len(x_batch) + np.random.normal(0, self.sigma2, size=nw.shape))\n\u001b[0;32m---> 15\u001b[0;31m                         for w, nw in zip(self.weights, nabla_w)]\n\u001b[0m\u001b[1;32m     16\u001b[0m         self.biases = [b-eta*(nb /len(x_batch) + np.random.normal(0, self.sigma2, size=nb.shape))\n\u001b[1;32m     17\u001b[0m                        for b, nb in zip(self.biases, nabla_b)]\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"FJA0rqyHXyKC"},"source":["L1"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":485},"id":"W3jnvzwvX9Vd","executionInfo":{"status":"error","timestamp":1638835891751,"user_tz":-60,"elapsed":39283,"user":{"displayName":"Bartłomiej Krzepkowski","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14471650214675903305"}},"outputId":"afe6d8ad-ed48-41fb-c5de-5ff6fd66adf4"},"source":["class Network_L1(Network_):\n","  def __init__(self, sizes, act_name, alpha):\n","    super(Network_L1, self).__init__(sizes, act_name)\n","    self.alpha = alpha\n","\n","  def update_mini_batch(self, x_batch, y_batch, eta):\n","        # Update networks weights and biases by applying a single step\n","        # of gradient descent using backpropagation to compute the gradient.\n","        # The gradient is computed for a mini_batch.\n","        # eta is the learning rate\n","        nabla_b, nabla_w = self.backprop(x_batch.T, y_batch.T)\n","        self.weights = [w-eta*self.alpha*np.sign(np.where(abs(w)>self.alpha,w,0))-(eta/len(x_batch))*nw \n","                        for w, nw in zip(self.weights, nabla_w)]\n","        self.biases = [b-(eta/len(x_batch))*nb \n","                       for b, nb in zip(self.biases, nabla_b)]\n","\n","network2 = Network_L1([784,100,30,10], act_name='relu', alpha=0.0001)\n","network2.SGD((x_train, y_train), epochs=50, mini_batch_size=100, eta=0.05,\n","            test_data=(x_test, y_test), step=2)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Accuracy: 0.9244\n","Epoch: 2, Accuracy: 0.952\n","Epoch: 4, Accuracy: 0.9589\n","Epoch: 6, Accuracy: 0.9656\n","Epoch: 8, Accuracy: 0.9657\n","Epoch: 10, Accuracy: 0.9667\n","Epoch: 12, Accuracy: 0.969\n","Epoch: 14, Accuracy: 0.9715\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-cd4d5637ef87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mnetwork2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork_L1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m network2.SGD((x_train, y_train), epochs=50, mini_batch_size=100, eta=0.05,\n\u001b[0;32m---> 19\u001b[0;31m             test_data=(x_test, y_test), step=2)\n\u001b[0m","\u001b[0;32m<ipython-input-4-335264b81c49>\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(self, training_data, epochs, mini_batch_size, eta, test_data, p, step)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mx_mini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0my_mini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_mini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-cd4d5637ef87>\u001b[0m in \u001b[0;36mupdate_mini_batch\u001b[0;34m(self, x_batch, y_batch, eta)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mnabla_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnabla_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         self.weights = [w-eta*self.alpha*np.sign(np.where(abs(w)>self.alpha,w,0))-(eta/len(x_batch))*nw \n\u001b[0;32m---> 13\u001b[0;31m                         for w, nw in zip(self.weights, nabla_w)]\n\u001b[0m\u001b[1;32m     14\u001b[0m         self.biases = [b-(eta/len(x_batch))*nb \n\u001b[1;32m     15\u001b[0m                        for b, nb in zip(self.biases, nabla_b)]\n","\u001b[0;32m<ipython-input-8-cd4d5637ef87>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mnabla_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnabla_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         self.weights = [w-eta*self.alpha*np.sign(np.where(abs(w)>self.alpha,w,0))-(eta/len(x_batch))*nw \n\u001b[0;32m---> 13\u001b[0;31m                         for w, nw in zip(self.weights, nabla_w)]\n\u001b[0m\u001b[1;32m     14\u001b[0m         self.biases = [b-(eta/len(x_batch))*nb \n\u001b[1;32m     15\u001b[0m                        for b, nb in zip(self.biases, nabla_b)]\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"ltjbfjzEsM4e"},"source":["Weight Decay (L2)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":693},"id":"_Am8JRSxsKJh","executionInfo":{"status":"error","timestamp":1638835989144,"user_tz":-60,"elapsed":72402,"user":{"displayName":"Bartłomiej Krzepkowski","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14471650214675903305"}},"outputId":"e349cefc-410c-44c6-9148-c92e34023d17"},"source":["class Network_L2(Network_):\n","  def __init__(self, sizes, act_name, alpha):\n","    super(Network_L2, self).__init__(sizes, act_name)\n","    self.alpha = alpha\n","\n","  def update_mini_batch(self, x_batch, y_batch, eta):\n","        # Update networks weights and biases by applying a single step\n","        # of gradient descent using backpropagation to compute the gradient.\n","        # The gradient is computed for a mini_batch.\n","        # eta is the learning rate\n","        nabla_b, nabla_w = self.backprop(x_batch.T, y_batch.T)\n","        self.weights = [w*(1-eta*self.alpha)-(eta/len(x_batch))*nw \n","                        for w, nw in zip(self.weights, nabla_w)]\n","        self.biases = [b-(eta/len(x_batch))*nb \n","                       for b, nb in zip(self.biases, nabla_b)]\n","\n","network3 = Network_L2([784,100,30,10], act_name='relu', alpha=0.0001)\n","network3.SGD((x_train, y_train), epochs=50, mini_batch_size=100, eta=0.05,\n","            test_data=(x_test, y_test), step=2)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Accuracy: 0.9262\n","Epoch: 2, Accuracy: 0.9515\n","Epoch: 4, Accuracy: 0.9585\n","Epoch: 6, Accuracy: 0.9643\n","Epoch: 8, Accuracy: 0.9675\n","Epoch: 10, Accuracy: 0.9662\n","Epoch: 12, Accuracy: 0.9693\n","Epoch: 14, Accuracy: 0.9708\n","Epoch: 16, Accuracy: 0.9735\n","Epoch: 18, Accuracy: 0.9739\n","Epoch: 20, Accuracy: 0.9739\n","Epoch: 22, Accuracy: 0.9755\n","Epoch: 24, Accuracy: 0.9758\n","Epoch: 26, Accuracy: 0.9742\n","Epoch: 28, Accuracy: 0.9737\n","Epoch: 30, Accuracy: 0.9757\n","Epoch: 32, Accuracy: 0.9749\n","Epoch: 34, Accuracy: 0.9751\n","Epoch: 36, Accuracy: 0.9751\n","Epoch: 38, Accuracy: 0.9743\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-7af8d765d190>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mnetwork3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork_L2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m network3.SGD((x_train, y_train), epochs=50, mini_batch_size=100, eta=0.05,\n\u001b[0;32m---> 19\u001b[0;31m             test_data=(x_test, y_test), step=2)\n\u001b[0m","\u001b[0;32m<ipython-input-4-335264b81c49>\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(self, training_data, epochs, mini_batch_size, eta, test_data, p, step)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mx_mini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0my_mini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_mini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-7af8d765d190>\u001b[0m in \u001b[0;36mupdate_mini_batch\u001b[0;34m(self, x_batch, y_batch, eta)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# The gradient is computed for a mini_batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# eta is the learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mnabla_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnabla_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         self.weights = [w*(1-eta*self.alpha)-(eta/len(x_batch))*nw \n\u001b[1;32m     13\u001b[0m                         for w, nw in zip(self.weights, nabla_w)]\n","\u001b[0;32m<ipython-input-4-335264b81c49>\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(self, x_batch, y_batch)\u001b[0m\n\u001b[1;32m     51\u001b[0m           \u001b[0mdLdhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdLdh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mdelta_nabla_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdLdh\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdLdh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdLdhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         delta_nabla_b = [dLdh.sum(axis=1)[:, np.newaxis] \n\u001b[1;32m     55\u001b[0m                          for dLdh in reversed(dLdhs)]\n","\u001b[0;32m<ipython-input-4-335264b81c49>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     51\u001b[0m           \u001b[0mdLdhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdLdh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mdelta_nabla_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdLdh\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdLdh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdLdhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         delta_nabla_b = [dLdh.sum(axis=1)[:, np.newaxis] \n\u001b[1;32m     55\u001b[0m                          for dLdh in reversed(dLdhs)]\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"vM0sY2ldrOQ2"},"source":["Momentum"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":676},"id":"YSKNzttMt5lV","executionInfo":{"status":"error","timestamp":1638836138334,"user_tz":-60,"elapsed":78944,"user":{"displayName":"Bartłomiej Krzepkowski","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14471650214675903305"}},"outputId":"5fe9b8c3-3e90-4279-c828-92aa342a57cc"},"source":["class Network_M(Network_):\n","  def __init__(self, sizes, act_name, mu):\n","    super(Network_M, self).__init__(sizes, act_name)\n","    self.v_w = [np.zeros_like(w) for w in self.weights]\n","    self.v_b = [np.zeros_like(w) for w in self.biases]\n","    self.mu = mu\n","\n","  def update_mini_batch(self, x_batch, y_batch, eta):\n","        # Update networks weights and biases by applying a single step\n","        # of gradient descent using backpropagation to compute the gradient.\n","        # The gradient is computed for a mini_batch.\n","        # eta is the learning rate\n","        nabla_b, nabla_w = self.backprop(x_batch.T, y_batch.T)\n","        self.v_w = [self.mu * v + eta * nw / len(x_batch) for v, nw in zip(self.v_w, nabla_w)]\n","        self.weights = [w - v for w, v in zip(self.weights, self.v_w)]\n","        self.v_b = [self.mu * v + eta * nw / len(x_batch) for v, nw in zip(self.v_b, nabla_b)]\n","        self.biases = [b - v for b, v in zip(self.biases, self.v_b)]\n","\n","network4 = Network_M([784,100,30,10], act_name='relu', mu=0.9)\n","network4.SGD((x_train, y_train), epochs=50, mini_batch_size=100, eta=0.005,\n","            test_data=(x_test, y_test), step=2)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Accuracy: 0.9279\n","Epoch: 2, Accuracy: 0.9525\n","Epoch: 4, Accuracy: 0.9611\n","Epoch: 6, Accuracy: 0.9655\n","Epoch: 8, Accuracy: 0.9681\n","Epoch: 10, Accuracy: 0.9692\n","Epoch: 12, Accuracy: 0.9702\n","Epoch: 14, Accuracy: 0.9698\n","Epoch: 16, Accuracy: 0.9732\n","Epoch: 18, Accuracy: 0.9755\n","Epoch: 20, Accuracy: 0.9745\n","Epoch: 22, Accuracy: 0.9759\n","Epoch: 24, Accuracy: 0.9765\n","Epoch: 26, Accuracy: 0.9767\n","Epoch: 28, Accuracy: 0.977\n","Epoch: 30, Accuracy: 0.9762\n","Epoch: 32, Accuracy: 0.9761\n","Epoch: 34, Accuracy: 0.9765\n","Epoch: 36, Accuracy: 0.9761\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-7ec7c4e15ef1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mnetwork4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork_M\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m network4.SGD((x_train, y_train), epochs=50, mini_batch_size=100, eta=0.005,\n\u001b[0;32m---> 21\u001b[0;31m             test_data=(x_test, y_test), step=2)\n\u001b[0m","\u001b[0;32m<ipython-input-4-335264b81c49>\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(self, training_data, epochs, mini_batch_size, eta, test_data, p, step)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mx_mini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0my_mini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_mini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-7ec7c4e15ef1>\u001b[0m in \u001b[0;36mupdate_mini_batch\u001b[0;34m(self, x_batch, y_batch, eta)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# The gradient is computed for a mini_batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# eta is the learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mnabla_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnabla_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnw\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnabla_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-335264b81c49>\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(self, x_batch, y_batch)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mderiv_fs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m           \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m           \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'relu'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m           \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"b2sqY7C9t5Ni"},"source":["L2 + Momentum"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IQ4XblUheC8f","executionInfo":{"status":"ok","timestamp":1638836540804,"user_tz":-60,"elapsed":229506,"user":{"displayName":"Bartłomiej Krzepkowski","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14471650214675903305"}},"outputId":"521bdf29-e247-41fe-eb66-004de46436fc"},"source":["class Network_M_L2(Network_):\n","  def __init__(self, sizes, act_name, alpha, mu):\n","    super(Network_M_L2, self).__init__(sizes, act_name)\n","    self.v_w = [np.zeros_like(w) for w in self.weights]\n","    self.v_b = [np.zeros_like(w) for w in self.biases]\n","    self.alpha = alpha\n","    self.mu = mu\n","\n","  def update_mini_batch(self, x_batch, y_batch, eta):\n","        # Update networks weights and biases by applying a single step\n","        # of gradient descent using backpropagation to compute the gradient.\n","        # The gradient is computed for a mini_batch.\n","        # eta is the learning rate\n","        nabla_b, nabla_w = self.backprop(x_batch.T, y_batch.T)\n","        nabla_w = [nw/len(x_batch) + self.alpha*w for nw, w in zip(nabla_w, self.weights)]\n","        self.v_w = [self.mu * v + eta * nw for v, nw in zip(self.v_w, nabla_w)]\n","        self.weights = [w - v for w, v in zip(self.weights, self.v_w)]\n","        self.v_b = [self.mu * v + eta * nw / len(x_batch) for v, nw in zip(self.v_b, nabla_b)]\n","        self.biases = [b - v for b, v in zip(self.biases, self.v_b)]\n","\n","network5 = Network_M_L2([784,100,30,10], act_name='relu', alpha=0.0001, mu=0.9)\n","network5.SGD((x_train, y_train), epochs=100, mini_batch_size=100, eta=0.01,\n","            test_data=(x_test, y_test), step=2)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Accuracy: 0.9431\n","Epoch: 2, Accuracy: 0.9619\n","Epoch: 4, Accuracy: 0.9655\n","Epoch: 6, Accuracy: 0.9714\n","Epoch: 8, Accuracy: 0.9731\n","Epoch: 10, Accuracy: 0.9722\n","Epoch: 12, Accuracy: 0.9729\n","Epoch: 14, Accuracy: 0.9735\n","Epoch: 16, Accuracy: 0.9736\n","Epoch: 18, Accuracy: 0.9743\n","Epoch: 20, Accuracy: 0.9756\n","Epoch: 22, Accuracy: 0.9766\n","Epoch: 24, Accuracy: 0.9777\n","Epoch: 26, Accuracy: 0.9759\n","Epoch: 28, Accuracy: 0.9762\n","Epoch: 30, Accuracy: 0.9768\n","Epoch: 32, Accuracy: 0.9775\n","Epoch: 34, Accuracy: 0.9771\n","Epoch: 36, Accuracy: 0.9779\n","Epoch: 38, Accuracy: 0.9777\n","Epoch: 40, Accuracy: 0.978\n","Epoch: 42, Accuracy: 0.9783\n","Epoch: 44, Accuracy: 0.978\n","Epoch: 46, Accuracy: 0.9777\n","Epoch: 48, Accuracy: 0.9775\n","Epoch: 50, Accuracy: 0.9777\n","Epoch: 52, Accuracy: 0.9776\n","Epoch: 54, Accuracy: 0.9781\n","Epoch: 56, Accuracy: 0.9775\n","Epoch: 58, Accuracy: 0.9786\n","Epoch: 60, Accuracy: 0.9781\n","Epoch: 62, Accuracy: 0.9787\n","Epoch: 64, Accuracy: 0.9788\n","Epoch: 66, Accuracy: 0.9778\n","Epoch: 68, Accuracy: 0.9785\n","Epoch: 70, Accuracy: 0.9781\n","Epoch: 72, Accuracy: 0.9778\n","Epoch: 74, Accuracy: 0.9787\n","Epoch: 76, Accuracy: 0.9785\n","Epoch: 78, Accuracy: 0.9787\n","Epoch: 80, Accuracy: 0.9788\n","Epoch: 82, Accuracy: 0.9792\n","Epoch: 84, Accuracy: 0.9788\n","Epoch: 86, Accuracy: 0.979\n","Epoch: 88, Accuracy: 0.9784\n","Epoch: 90, Accuracy: 0.9786\n","Epoch: 92, Accuracy: 0.9787\n","Epoch: 94, Accuracy: 0.9786\n","Epoch: 96, Accuracy: 0.9781\n","Epoch: 98, Accuracy: 0.9787\n"]}]},{"cell_type":"markdown","metadata":{"id":"mbklMHRgYWgG"},"source":["Nesterov's Momentum\n","\n","Nesterov Accelerated Gradients (NAG)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yNL_6S12YW34","executionInfo":{"status":"ok","timestamp":1637013912943,"user_tz":-60,"elapsed":78472,"user":{"displayName":"Bartłomiej Krzepkowski","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14471650214675903305"}},"outputId":"de71eccc-25e8-4df0-c6b0-0ff9e3735a01"},"source":["class Network_NAG(Network_):\n","  def __init__(self, sizes, act_name, mu):\n","    super(Network_NAG, self).__init__(sizes, act_name)\n","    self.v_w = [np.zeros_like(w) for w in self.weights]\n","    self.v_b = [np.zeros_like(w) for w in self.biases]\n","    self.mu = mu\n","\n","  def update_mini_batch(self, x_batch, y_batch, eta):\n","        # Update networks weights and biases by applying a single step\n","        # of gradient descent using backpropagation to compute the gradient.\n","        # The gradient is computed for a mini_batch.\n","        # eta is the learning rate\n","\n","        # A PROPER WAY?\n","        # for i in range(len(self.biases)):\n","        #   w_org, b_org = self.weights[i].copy(), self.biases[i].copy()\n","        #   self.weights[i] -= self.mu*self.v_w[i]\n","        #   self.biases[i] -= self.mu*self.v_b[i]\n","        #   nabla_b, nabla_w = self.backprop(x_batch.T, y_batch.T)\n","        #   self.v_w[i] = self.mu*self.v_w[i] + (eta/len(x_batch))*nabla_w[i]\n","        #   self.v_b[i] = self.mu*self.v_b[i] + (eta/len(x_batch))*nabla_b[i]\n","        #   self.weights[i], self.biases[i] = w_org, b_org\n","\n","        # self.weights = [w - v for w, v in zip(self.weights, self.v_w)]\n","        # self.biases = [b - v for b, v in zip(self.biases, self.v_b)]\n","\n","        self.weights = [w - self.mu*v for w, v in zip(self.weights, self.v_w)]\n","        self.biases = [b - self.mu*v for b, v in zip(self.biases, self.v_b)]\n","        nabla_b, nabla_w = self.backprop(x_batch.T, y_batch.T)\n","        self.weights = [w + self.mu*v for w, v in zip(self.weights, self.v_w)]\n","        self.biases = [b + self.mu*v for b, v in zip(self.biases, self.v_b)]\n","\n","        self.v_w = [self.mu*v + (eta/len(x_batch))*nw for v, nw in zip(self.v_w, nabla_w)]\n","        self.v_b = [self.mu*v + (eta/len(x_batch))*nb for v, nb in zip(self.v_b, nabla_b)]\n","\n","        self.weights = [w - v for w, v in zip(self.weights, self.v_w)]\n","        self.biases = [b - v for b, v in zip(self.biases, self.v_b)]\n","\n","network6 = Network_NAG([784,100,30,10], act_name='sigmoid', mu=0.9)\n","network6.SGD((x_train, y_train), epochs=150, mini_batch_size=100, eta=0.05,\n","            test_data=(x_test, y_test))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Accuracy: 0.9112\n","Epoch: 10, Accuracy: 0.9466\n","Epoch: 20, Accuracy: 0.9514\n","Epoch: 30, Accuracy: 0.9509\n","Epoch: 40, Accuracy: 0.9526\n"]}]},{"cell_type":"markdown","metadata":{"id":"KW6d9uUuZLWm"},"source":["AdaGrad"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SwIneFTYZO38","executionInfo":{"status":"ok","timestamp":1637014054852,"user_tz":-60,"elapsed":46573,"user":{"displayName":"Bartłomiej Krzepkowski","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14471650214675903305"}},"outputId":"4d74e4a7-b86a-4e23-b881-b0da45a33233"},"source":["class Network_Adagrad(Network_):\n","  def __init__(self, sizes, act_name, mu, eps):\n","    super(Network_Adagrad, self).__init__(sizes, act_name)\n","    self.m_b = [np.zeros_like(w) for w in self.biases]\n","    self.m_w = [np.zeros_like(w) for w in self.weights]\n","    self.eps = eps\n","    self.mu = mu\n","\n","  def update_mini_batch(self, x_batch, y_batch, eta):\n","        # Update networks weights and biases by applying a single step\n","        # of gradient descent using backpropagation to compute the gradient.\n","        # The gradient is computed for a mini_batch.\n","        # eta is the learning rate\n","\n","        nabla_b, nabla_w = self.backprop(x_batch.T, y_batch.T)\n","\n","        self.m_b = [m + (nb/len(x_batch))**2 for m, nb in zip(self.m_b, nabla_b)]\n","        self.biases = [b - (eta / np.sqrt(m + self.eps)) * nb / len(x_batch)\\\n","                       for b, nb, m in zip(self.biases, nabla_b, self.m_b)]\n","\n","        self.m_w = [m + (nb/len(x_batch))**2 for m, nb in zip(self.m_w, nabla_w)]\n","        self.weights = [w - (eta/np.sqrt(m + self.eps)) * nw / len(x_batch)\\\n","                        for w, nw, m in zip(self.weights, nabla_w, self.m_w)]\n","\n","network7 = Network_Adagrad([784,100,30,10], act_name='sigmoid', mu=0.9, eps=1e-8)\n","network7.SGD((x_train, y_train), epochs=150, mini_batch_size=100, eta=0.05,\n","            test_data=(x_test, y_test))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Accuracy: 0.9047\n","Epoch: 10, Accuracy: 0.943\n","Epoch: 20, Accuracy: 0.9464\n","Epoch: 30, Accuracy: 0.9491\n","Epoch: 40, Accuracy: 0.9495\n"]}]},{"cell_type":"markdown","metadata":{"id":"n1BnHMgQjHJt"},"source":["Adadelta"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gQ7frtMmjLbK","executionInfo":{"status":"ok","timestamp":1638743276662,"user_tz":-60,"elapsed":596591,"user":{"displayName":"Bartłomiej Krzepkowski","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14471650214675903305"}},"outputId":"abccfc3f-c031-4c89-a9e1-b25363b532dd"},"source":["class Network_Adadelta(Network_):\n","  def __init__(self, sizes, act_name, mu, eps):\n","    super(Network_Adadelta, self).__init__(sizes, act_name)\n","    self.m_b = [np.zeros_like(w) for w in self.biases]\n","    self.m_w = [np.zeros_like(w) for w in self.weights]\n","    self.dm_b = [np.zeros_like(w) for w in self.biases]\n","    self.dm_w = [np.zeros_like(w) for w in self.weights]\n","    self.eps = eps\n","    self.mu = mu\n","\n","  def update_mini_batch(self, x_batch, y_batch, eta):\n","        # Update networks weights and biases by applying a single step\n","        # of gradient descent using backpropagation to compute the gradient.\n","        # The gradient is computed for a mini_batch.\n","        # eta is the learning rate\n","\n","        nabla_b, nabla_w = self.backprop(x_batch.T, y_batch.T)\n","        \n","        self.m_b = [self.mu * m + (1 - self.mu) * (nb/len(x_batch))**2 for m, nb in zip(self.m_b, nabla_b)]\n","        self.dm_b = [self.mu * dm + (1 - self.mu) * ((eta / np.sqrt(m + self.eps)) * (nb/len(x_batch)))**2 for dm, m, nb in zip(self.dm_b, self.m_b, nabla_b)]\n","        self.biases = [b - (np.sqrt(dm + self.eps) / np.sqrt(m + self.eps)) * (nb/len(x_batch)) for b, nb, m, dm in zip(self.biases, nabla_b, self.m_b, self.dm_b)]\n","        \n","        self.m_w = [self.mu * m + (1 - self.mu) * (nw/len(x_batch))**2 for m, nw in zip(self.m_w, nabla_w)]\n","        self.dm_w = [self.mu * dm + (1 - self.mu) * ((eta / np.sqrt(m + self.eps)) * (nw/len(x_batch)))**2 for dm, m, nw in zip(self.dm_w, self.m_w, nabla_w)]\n","        self.weights = [b - (np.sqrt(dm + self.eps)/np.sqrt(m + self.eps)) * (nw/len(x_batch)) for b, nw, m, dm in zip(self.weights, nabla_w, self.m_w, self.dm_b)]\n","\n","network8 = Network_Adadelta([784,100,30,10], act_name='sigmoid', mu=0.9, eps=1e-8)\n","network8.SGD((x_train, y_train), epochs=150, mini_batch_size=100, eta=0.05,\n","            test_data=(x_test, y_test), step=2)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Accuracy: 0.924\n","Epoch: 2, Accuracy: 0.9338\n","Epoch: 4, Accuracy: 0.9414\n","Epoch: 6, Accuracy: 0.9486\n","Epoch: 8, Accuracy: 0.9482\n","Epoch: 10, Accuracy: 0.9402\n","Epoch: 12, Accuracy: 0.9548\n","Epoch: 14, Accuracy: 0.9544\n","Epoch: 16, Accuracy: 0.949\n","Epoch: 18, Accuracy: 0.9548\n","Epoch: 20, Accuracy: 0.9574\n","Epoch: 22, Accuracy: 0.9506\n","Epoch: 24, Accuracy: 0.9558\n","Epoch: 26, Accuracy: 0.9588\n","Epoch: 28, Accuracy: 0.9546\n","Epoch: 30, Accuracy: 0.9514\n","Epoch: 32, Accuracy: 0.9546\n","Epoch: 34, Accuracy: 0.9587\n","Epoch: 36, Accuracy: 0.959\n","Epoch: 38, Accuracy: 0.9592\n","Epoch: 40, Accuracy: 0.9577\n","Epoch: 42, Accuracy: 0.9599\n","Epoch: 44, Accuracy: 0.9587\n","Epoch: 46, Accuracy: 0.9641\n","Epoch: 48, Accuracy: 0.9626\n","Epoch: 50, Accuracy: 0.9603\n","Epoch: 52, Accuracy: 0.9581\n","Epoch: 54, Accuracy: 0.9578\n","Epoch: 56, Accuracy: 0.9627\n","Epoch: 58, Accuracy: 0.9621\n","Epoch: 60, Accuracy: 0.9575\n","Epoch: 62, Accuracy: 0.9602\n","Epoch: 64, Accuracy: 0.9608\n","Epoch: 66, Accuracy: 0.9586\n","Epoch: 68, Accuracy: 0.9561\n","Epoch: 70, Accuracy: 0.9638\n","Epoch: 72, Accuracy: 0.961\n","Epoch: 74, Accuracy: 0.961\n","Epoch: 76, Accuracy: 0.9641\n","Epoch: 78, Accuracy: 0.9625\n","Epoch: 80, Accuracy: 0.9627\n","Epoch: 82, Accuracy: 0.9589\n","Epoch: 84, Accuracy: 0.9616\n","Epoch: 86, Accuracy: 0.9649\n","Epoch: 88, Accuracy: 0.9593\n","Epoch: 90, Accuracy: 0.9646\n","Epoch: 92, Accuracy: 0.9611\n","Epoch: 94, Accuracy: 0.9637\n","Epoch: 96, Accuracy: 0.9621\n","Epoch: 98, Accuracy: 0.9595\n","Epoch: 100, Accuracy: 0.9589\n","Epoch: 102, Accuracy: 0.96\n","Epoch: 104, Accuracy: 0.9589\n","Epoch: 106, Accuracy: 0.9633\n","Epoch: 108, Accuracy: 0.9624\n","Epoch: 110, Accuracy: 0.9617\n","Epoch: 112, Accuracy: 0.9611\n","Epoch: 114, Accuracy: 0.9599\n","Epoch: 116, Accuracy: 0.9654\n","Epoch: 118, Accuracy: 0.9617\n","Epoch: 120, Accuracy: 0.9655\n","Epoch: 122, Accuracy: 0.9606\n","Epoch: 124, Accuracy: 0.9631\n","Epoch: 126, Accuracy: 0.9641\n","Epoch: 128, Accuracy: 0.9627\n","Epoch: 130, Accuracy: 0.965\n","Epoch: 132, Accuracy: 0.9607\n","Epoch: 134, Accuracy: 0.9642\n","Epoch: 136, Accuracy: 0.9601\n","Epoch: 138, Accuracy: 0.9637\n","Epoch: 140, Accuracy: 0.9643\n","Epoch: 142, Accuracy: 0.9625\n","Epoch: 144, Accuracy: 0.9646\n","Epoch: 146, Accuracy: 0.9603\n","Epoch: 148, Accuracy: 0.9628\n"]}]},{"cell_type":"markdown","metadata":{"id":"T8iHh-6AadjM"},"source":["RMSProp"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ORQAOVXradIp","executionInfo":{"status":"ok","timestamp":1638744038635,"user_tz":-60,"elapsed":455921,"user":{"displayName":"Bartłomiej Krzepkowski","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14471650214675903305"}},"outputId":"90096c36-3c2e-49c5-849e-4fa699c10bf3"},"source":["class Network_RMSProp(Network_):\n","  def __init__(self, sizes, act_name, mu, eps):\n","    super(Network_RMSProp, self).__init__(sizes, act_name)\n","    self.m_b = [np.zeros_like(w) for w in self.biases]\n","    self.m_w = [np.zeros_like(w) for w in self.weights]\n","    self.eps = eps\n","    self.mu = mu\n","\n","  def update_mini_batch(self, x_batch, y_batch, eta):\n","        # Update networks weights and biases by applying a single step\n","        # of gradient descent using backpropagation to compute the gradient.\n","        # The gradient is computed for a mini_batch.\n","        # eta is the learning rate\n","\n","        nabla_b, nabla_w = self.backprop(x_batch.T, y_batch.T)\n","        \n","        self.m_b = [self.mu * m + (1 - self.mu) * (nb/len(x_batch))**2 \\\n","                    for m, nb in zip(self.m_b, nabla_b)]\n","        self.biases = [b - (eta / np.sqrt(m + self.eps)) * (nb/len(x_batch)) \\\n","                       for b, nb, m in zip(self.biases, nabla_b, self.m_b)]\n","        \n","        self.m_w = [self.mu * m + (1 - self.mu) * (nw/len(x_batch))**2 \\\n","                    for m, nw in zip(self.m_w, nabla_w)]\n","        self.weights = [b - (eta/np.sqrt(m + self.eps)) * (nw/len(x_batch)) \\\n","                        for b, nw, m in zip(self.weights, nabla_w, self.m_w)]\n","\n","network8 = Network_RMSProp([784,100,30,10], act_name='sigmoid', mu=0.9, eps=1e-8)\n","network8.SGD((x_train, y_train), epochs=150, mini_batch_size=100, eta=0.05,\n","            test_data=(x_test, y_test), step=2)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Accuracy: 0.9124\n","Epoch: 2, Accuracy: 0.9339\n","Epoch: 4, Accuracy: 0.9472\n","Epoch: 6, Accuracy: 0.9516\n","Epoch: 8, Accuracy: 0.9511\n","Epoch: 10, Accuracy: 0.9552\n","Epoch: 12, Accuracy: 0.9553\n","Epoch: 14, Accuracy: 0.9548\n","Epoch: 16, Accuracy: 0.955\n","Epoch: 18, Accuracy: 0.9581\n","Epoch: 20, Accuracy: 0.9612\n","Epoch: 22, Accuracy: 0.9572\n","Epoch: 24, Accuracy: 0.9592\n","Epoch: 26, Accuracy: 0.9611\n","Epoch: 28, Accuracy: 0.9604\n","Epoch: 30, Accuracy: 0.9578\n","Epoch: 32, Accuracy: 0.9619\n","Epoch: 34, Accuracy: 0.9607\n","Epoch: 36, Accuracy: 0.964\n","Epoch: 38, Accuracy: 0.964\n","Epoch: 40, Accuracy: 0.963\n","Epoch: 42, Accuracy: 0.9659\n","Epoch: 44, Accuracy: 0.9654\n","Epoch: 46, Accuracy: 0.9644\n","Epoch: 48, Accuracy: 0.9629\n","Epoch: 50, Accuracy: 0.9612\n","Epoch: 52, Accuracy: 0.9639\n","Epoch: 54, Accuracy: 0.9635\n","Epoch: 56, Accuracy: 0.9614\n","Epoch: 58, Accuracy: 0.965\n","Epoch: 60, Accuracy: 0.9649\n","Epoch: 62, Accuracy: 0.9644\n","Epoch: 64, Accuracy: 0.9669\n","Epoch: 66, Accuracy: 0.9656\n","Epoch: 68, Accuracy: 0.9656\n","Epoch: 70, Accuracy: 0.9599\n","Epoch: 72, Accuracy: 0.9676\n","Epoch: 74, Accuracy: 0.9644\n","Epoch: 76, Accuracy: 0.9637\n","Epoch: 78, Accuracy: 0.9665\n","Epoch: 80, Accuracy: 0.9651\n","Epoch: 82, Accuracy: 0.9618\n","Epoch: 84, Accuracy: 0.9664\n","Epoch: 86, Accuracy: 0.9684\n","Epoch: 88, Accuracy: 0.9631\n","Epoch: 90, Accuracy: 0.9653\n","Epoch: 92, Accuracy: 0.9666\n","Epoch: 94, Accuracy: 0.9564\n","Epoch: 96, Accuracy: 0.9631\n","Epoch: 98, Accuracy: 0.9651\n","Epoch: 100, Accuracy: 0.964\n","Epoch: 102, Accuracy: 0.9674\n","Epoch: 104, Accuracy: 0.9679\n","Epoch: 106, Accuracy: 0.9662\n","Epoch: 108, Accuracy: 0.9679\n","Epoch: 110, Accuracy: 0.9617\n","Epoch: 112, Accuracy: 0.966\n","Epoch: 114, Accuracy: 0.9645\n","Epoch: 116, Accuracy: 0.9678\n","Epoch: 118, Accuracy: 0.9658\n","Epoch: 120, Accuracy: 0.9678\n","Epoch: 122, Accuracy: 0.9669\n","Epoch: 124, Accuracy: 0.9688\n","Epoch: 126, Accuracy: 0.9687\n","Epoch: 128, Accuracy: 0.9665\n","Epoch: 130, Accuracy: 0.9658\n","Epoch: 132, Accuracy: 0.9686\n","Epoch: 134, Accuracy: 0.9696\n","Epoch: 136, Accuracy: 0.9667\n","Epoch: 138, Accuracy: 0.9695\n","Epoch: 140, Accuracy: 0.9652\n","Epoch: 142, Accuracy: 0.9655\n","Epoch: 144, Accuracy: 0.9665\n","Epoch: 146, Accuracy: 0.9686\n","Epoch: 148, Accuracy: 0.967\n"]}]},{"cell_type":"markdown","metadata":{"id":"X3My47h7bCI8"},"source":["Adam"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yXqKiWzLZL4Q","executionInfo":{"status":"ok","timestamp":1637014558468,"user_tz":-60,"elapsed":56539,"user":{"displayName":"Bartłomiej Krzepkowski","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14471650214675903305"}},"outputId":"850e22bd-b4fe-4b89-f703-ec8e6e0483ef"},"source":["class Network_Adam(Network_):\n","  def __init__(self, sizes, act_name, beta1, beta2, eps):\n","    super(Network_Adam, self).__init__(sizes, act_name)\n","    self.m_w = [np.zeros_like(w) for w in self.weights]\n","    self.g_w = [np.zeros_like(w) for w in self.weights]\n","    self.m_b = [np.zeros_like(w) for w in self.biases]\n","    self.g_b = [np.zeros_like(w) for w in self.biases]\n","    self.beta1 = beta1\n","    self.beta2 = beta2\n","    self.eps = eps\n","    self.step = 1\n","\n","  def update_mini_batch(self, x_batch, y_batch, eta):\n","        # Update networks weights and biases by applying a single step\n","        # of gradient descent using backpropagation to compute the gradient.\n","        # The gradient is computed for a mini_batch.\n","        # eta is the learning rate\n","\n","        nabla_b, nabla_w = self.backprop(x_batch.T, y_batch.T)\n","        \n","        self.m_w = [self.beta1 * m + (1 - self.beta1) * (nw/len(x_batch))\\\n","                  for m, nw in zip(self.m_w, nabla_w)]\n","        self.g_w = [self.beta2 * g + (1 - self.beta2) * (nw/len(x_batch))**2\\\n","                  for g, nw in zip(self.g_w, nabla_w)]\n","        self.weights = [w - (eta / (np.sqrt(g/(1 - self.beta2 ** self.step)) + self.eps)) * m/(1 - self.beta1 ** self.step)\\\n","                        for w, m, g in zip(self.weights, self.m_w, self.g_w)]\n","\n","        self.m_b = [self.beta1 * m + (1 - self.beta1) * (nw/len(x_batch))\\\n","                  for m, nw in zip(self.m_b, nabla_b)]\n","        self.g_b = [self.beta2 * g + (1 - self.beta2) * (nw/len(x_batch))**2\\\n","                  for g, nw in zip(self.g_b, nabla_b)]\n","        self.biases = [w - (eta / (np.sqrt(g/(1 - self.beta2 ** self.step)) + self.eps)) * m/(1 - self.beta1 ** self.step)\\\n","                        for w, m, g in zip(self.biases, self.m_b, self.g_b)]\n","        self.step += 1\n","\n","network9 = Network_Adam([784,100,30,10], act_name='sigmoid', beta1=0.9, beta2=0.99, eps=1e-8)\n","network9.SGD((x_train, y_train), epochs=150, mini_batch_size=100, eta=0.05,\n","            test_data=(x_test, y_test))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Accuracy: 0.9192\n","Epoch: 10, Accuracy: 0.9442\n","Epoch: 20, Accuracy: 0.9485\n","Epoch: 30, Accuracy: 0.9512\n","Epoch: 40, Accuracy: 0.9563\n"]}]},{"cell_type":"markdown","metadata":{"id":"oym_8JX-wCKO"},"source":["AdaMax"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":954},"id":"qoMzgE9-wEIw","executionInfo":{"status":"error","timestamp":1638745190934,"user_tz":-60,"elapsed":224672,"user":{"displayName":"Bartłomiej Krzepkowski","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14471650214675903305"}},"outputId":"18d426e2-6c44-4118-9278-d49ca9beee65"},"source":["class Network_AdaMax(Network_):\n","  def __init__(self, sizes, act_name, beta1, beta2, eps):\n","    super(Network_AdaMax, self).__init__(sizes, act_name)\n","    self.m_w = [np.zeros_like(w) for w in self.weights]\n","    self.g_w = [np.zeros_like(w) for w in self.weights]\n","    self.m_b = [np.zeros_like(w) for w in self.biases]\n","    self.g_b = [np.zeros_like(w) for w in self.biases]\n","    self.beta1 = beta1\n","    self.beta2 = beta2\n","    self.eps = eps\n","    self.step = 1\n","\n","  def update_mini_batch(self, x_batch, y_batch, eta):\n","        # Update networks weights and biases by applying a single step\n","        # of gradient descent using backpropagation to compute the gradient.\n","        # The gradient is computed for a mini_batch.\n","        # eta is the learning rate\n","\n","        nabla_b, nabla_w = self.backprop(x_batch.T, y_batch.T)\n","        \n","        self.m_w = [self.beta1 * m + (1 - self.beta1) * (nw/len(x_batch)) for m, nw in zip(self.m_w, nabla_w)]\n","        self.g_w = [np.maximum(self.beta2 * g, np.abs(nw / len(x_batch))) for g, nw in zip(self.g_w, nabla_w)]\n","                  \n","        self.weights = [w - (eta / (g+self.eps)) * m / (1 - self.beta1 ** self.step)\\\n","                        for w, m, g in zip(self.weights, self.m_w, self.g_w)]\n","\n","        self.m_b = [self.beta1 * m + (1 - self.beta1) * (nb/len(x_batch)) for m, nb in zip(self.m_b, nabla_b)]\n","        self.g_b = [np.maximum(self.beta2 * g, np.abs(nb/len(x_batch))) for g, nb in zip(self.g_b, nabla_b)]\n","        self.biases = [w - (eta / (g+self.eps)) * m / (1 - self.beta1 ** self.step)\\\n","                        for w, m, g in zip(self.biases, self.m_b, self.g_b)]\n","        self.step += 1\n","\n","network9 = Network_AdaMax([784,100,30,10], act_name='sigmoid', beta1=0.9, beta2=0.99, eps=1e-8)\n","network9.SGD((x_train, y_train), epochs=150, mini_batch_size=100, eta=0.05,\n","            test_data=(x_test, y_test), step=2)"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Accuracy: 0.9319\n","Epoch: 2, Accuracy: 0.9514\n","Epoch: 4, Accuracy: 0.9615\n","Epoch: 6, Accuracy: 0.9598\n","Epoch: 8, Accuracy: 0.963\n","Epoch: 10, Accuracy: 0.967\n","Epoch: 12, Accuracy: 0.9659\n","Epoch: 14, Accuracy: 0.9684\n","Epoch: 16, Accuracy: 0.9626\n","Epoch: 18, Accuracy: 0.9689\n","Epoch: 20, Accuracy: 0.9674\n","Epoch: 22, Accuracy: 0.9671\n","Epoch: 24, Accuracy: 0.9669\n","Epoch: 26, Accuracy: 0.9683\n","Epoch: 28, Accuracy: 0.9681\n","Epoch: 30, Accuracy: 0.9662\n","Epoch: 32, Accuracy: 0.9691\n","Epoch: 34, Accuracy: 0.9676\n","Epoch: 36, Accuracy: 0.9665\n","Epoch: 38, Accuracy: 0.9666\n","Epoch: 40, Accuracy: 0.9691\n","Epoch: 42, Accuracy: 0.9677\n","Epoch: 44, Accuracy: 0.9704\n","Epoch: 46, Accuracy: 0.9682\n","Epoch: 48, Accuracy: 0.9682\n","Epoch: 50, Accuracy: 0.9679\n","Epoch: 52, Accuracy: 0.9682\n","Epoch: 54, Accuracy: 0.9671\n","Epoch: 56, Accuracy: 0.9684\n","Epoch: 58, Accuracy: 0.9689\n","Epoch: 60, Accuracy: 0.9701\n","Epoch: 62, Accuracy: 0.9668\n","Epoch: 64, Accuracy: 0.9696\n","Epoch: 66, Accuracy: 0.9692\n","Epoch: 68, Accuracy: 0.9689\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-621c467f8231>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mnetwork9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork_Adam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m network9.SGD((x_train, y_train), epochs=150, mini_batch_size=100, eta=0.05,\n\u001b[0;32m---> 33\u001b[0;31m             test_data=(x_test, y_test), step=2)\n\u001b[0m","\u001b[0;32m<ipython-input-3-43388874850f>\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(self, training_data, epochs, mini_batch_size, eta, test_data, p, step)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mx_mini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0my_mini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_mini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-621c467f8231>\u001b[0m in \u001b[0;36mupdate_mini_batch\u001b[0;34m(self, x_batch, y_batch, eta)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# eta is the learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mnabla_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnabla_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnw\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnabla_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-43388874850f>\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(self, x_batch, y_batch)\u001b[0m\n\u001b[1;32m     51\u001b[0m           \u001b[0mdLdhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdLdh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mdelta_nabla_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdLdh\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdLdh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdLdhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         delta_nabla_b = [dLdh.sum(axis=1)[:, np.newaxis] \n\u001b[1;32m     55\u001b[0m                          for dLdh in reversed(dLdhs)]\n","\u001b[0;32m<ipython-input-3-43388874850f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     51\u001b[0m           \u001b[0mdLdhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdLdh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mdelta_nabla_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdLdh\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdLdh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdLdhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         delta_nabla_b = [dLdh.sum(axis=1)[:, np.newaxis] \n\u001b[1;32m     55\u001b[0m                          for dLdh in reversed(dLdhs)]\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"SgytNvS801Wa"},"source":["Nadam"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":433},"id":"9t-JILp5yzTG","executionInfo":{"status":"error","timestamp":1638835072765,"user_tz":-60,"elapsed":37875,"user":{"displayName":"Bartłomiej Krzepkowski","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14471650214675903305"}},"outputId":"83491dc7-7975-4234-8a5f-a8d8a8c01eb3"},"source":["class Network_Nadam(Network_):\n","  def __init__(self, sizes, act_name, beta1, beta2, eps):\n","    super(Network_Nadam, self).__init__(sizes, act_name)\n","    self.m_w = [np.zeros_like(w) for w in self.weights]\n","    self.g_w = [np.zeros_like(w) for w in self.weights]\n","    self.m_b = [np.zeros_like(w) for w in self.biases]\n","    self.g_b = [np.zeros_like(w) for w in self.biases]\n","    self.beta1 = beta1\n","    self.beta2 = beta2\n","    self.eps = eps\n","    self.step = 1\n","\n","  def update_mini_batch(self, x_batch, y_batch, eta):\n","        # Update networks weights and biases by applying a single step\n","        # of gradient descent using backpropagation to compute the gradient.\n","        # The gradient is computed for a mini_batch.\n","        # eta is the learning rate\n","\n","        nabla_b, nabla_w = self.backprop(x_batch.T, y_batch.T)\n","        \n","        self.m_w = [self.beta1 * m + (1 - self.beta1) * (nw/len(x_batch))\\\n","                  for m, nw in zip(self.m_w, nabla_w)]\n","        self.g_w = [self.beta2 * g + (1 - self.beta2) * (nw/len(x_batch))**2\\\n","                  for g, nw in zip(self.g_w, nabla_w)]\n","        self.weights = [w - (eta / (np.sqrt(g/(1 - self.beta2 ** self.step)) + self.eps)) * (self.beta1 * m + (1 - self.beta1) * (nw/len(x_batch))**2)/(1 - self.beta1 ** self.step)\\\n","                        for w, m, g, nw in zip(self.weights, self.m_w, self.g_w, nabla_w)]\n","\n","        self.m_b = [self.beta1 * m + (1 - self.beta1) * (nw/len(x_batch))\\\n","                  for m, nw in zip(self.m_b, nabla_b)]\n","        self.g_b = [self.beta2 * g + (1 - self.beta2) * (nw/len(x_batch))**2\\\n","                  for g, nw in zip(self.g_b, nabla_b)]\n","        self.biases = [w - (eta / (np.sqrt(g/(1 - self.beta2 ** self.step)) + self.eps)) * (self.beta1 * m + (1 - self.beta1) * (nb/len(x_batch))**2)/(1 - self.beta1 ** self.step)\\\n","                        for w, m, g, nb in zip(self.biases, self.m_b, self.g_b, nabla_b)]\n","        self.step += 1\n","\n","network9 = Network_Nadam([784,100,30,10], act_name='relu', beta1=0.9, beta2=0.99, eps=1e-8)\n","network9.SGD((x_train, y_train), epochs=150, mini_batch_size=100, eta=0.05,\n","            test_data=(x_test, y_test), step=2)"],"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Accuracy: 0.5792\n","Epoch: 2, Accuracy: 0.8905\n","Epoch: 4, Accuracy: 0.9156\n","Epoch: 6, Accuracy: 0.9203\n","Epoch: 8, Accuracy: 0.924\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-95-445826e11efa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mnetwork9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork_Nadam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m network9.SGD((x_train, y_train), epochs=150, mini_batch_size=100, eta=0.05,\n\u001b[0;32m---> 32\u001b[0;31m             test_data=(x_test, y_test), step=2)\n\u001b[0m","\u001b[0;32m<ipython-input-91-335264b81c49>\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(self, training_data, epochs, mini_batch_size, eta, test_data, p, step)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mx_mini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0my_mini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_mini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-95-445826e11efa>\u001b[0m in \u001b[0;36mupdate_mini_batch\u001b[0;34m(self, x_batch, y_batch, eta)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# eta is the learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mnabla_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnabla_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnw\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m                  \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnabla_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-91-335264b81c49>\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(self, x_batch, y_batch)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mderiv_fs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m           \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m           \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'relu'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m           \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"mRWsqIP9J9tE"},"source":[" nabla_b, nabla_w = self.backprop(x_batch.T, y_batch.T)\n","        \n","        self.m_w = [self.beta1 * m + (1 - self.beta1) * (nw/len(x_batch))\\\n","                  for m, nw in zip(self.m_w, nabla_w)]\n","        self.g_w = [self.beta2 * g + (1 - self.beta2) * (nw/len(x_batch))**2\\\n","                  for g, nw in zip(self.g_w, nabla_w)]\n","        self.weights = [w - (eta / (np.sqrt(g/(1 - self.beta2 ** self.step)) + self.eps)) * (self.beta1 * m + (1 - self.beta1) * nw)/(1 - self.beta1 ** self.step)\\\n","                        for w, m, g nw in zip(self.weights, self.m_w, self.g_w, nabla_w)]\n","\n","        self.m_b = [self.beta1 * m + (1 - self.beta1) * (nw/len(x_batch))\\\n","                  for m, nw in zip(self.m_b, nabla_b)]\n","        self.g_b = [self.beta2 * g + (1 - self.beta2) * (nw/len(x_batch))**2\\\n","                  for g, nw in zip(self.g_b, nabla_b)]\n","        self.biases = [w - (eta / (np.sqrt(g/(1 - self.beta2 ** self.step)) + self.eps)) * (self.beta1 * m + (1 - self.beta1) * nb)/(1 - self.beta1 ** self.step)\\\n","                        for w, m, g, nb in zip(self.biases, self.m_b, self.g_b, nabla_b)]\n","        self.step += 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hkLEz3xo4HTW"},"source":["AMSGrad"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ssFq17y_4Kep","executionInfo":{"status":"ok","timestamp":1638748167126,"user_tz":-60,"elapsed":540585,"user":{"displayName":"Bartłomiej Krzepkowski","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14471650214675903305"}},"outputId":"5da5a926-b8ec-469a-fa93-009b3717fa71"},"source":["class Network_AMSGrad(Network_):\n","  def __init__(self, sizes, act_name, beta1, beta2, eps):\n","    super(Network_AMSGrad, self).__init__(sizes, act_name)\n","    self.m_w = [np.zeros_like(w) for w in self.weights]\n","    self.g_w = [np.zeros_like(w) for w in self.weights]\n","    self.g_w_hat = [np.zeros_like(w) for w in self.weights]\n","    self.m_b = [np.zeros_like(b) for b in self.biases]\n","    self.g_b = [np.zeros_like(b) for b in self.biases]\n","    self.g_b_hat = [np.zeros_like(b) for b in self.biases]\n","    self.beta1 = beta1\n","    self.beta2 = beta2\n","    self.eps = eps\n","    self.step = 1\n","\n","  def update_mini_batch(self, x_batch, y_batch, eta):\n","        # Update networks weights and biases by applying a single step\n","        # of gradient descent using backpropagation to compute the gradient.\n","        # The gradient is computed for a mini_batch.\n","        # eta is the learning rate\n","\n","        nabla_b, nabla_w = self.backprop(x_batch.T, y_batch.T)\n","        \n","        self.m_w = [self.beta1 * m + (1 - self.beta1) * (nw/len(x_batch))\\\n","                  for m, nw in zip(self.m_w, nabla_w)]\n","        self.g_w = [self.beta2 * g + (1 - self.beta2) * (nw/len(x_batch))**2\\\n","                  for g, nw in zip(self.g_w, nabla_w)]\n","        self.g_w_hat = [np.maximum(g_hat, g) for g_hat, g in zip(self.g_w_hat, self.g_w)]\n","        self.weights = [w - (eta / (np.sqrt(g/(1 - self.beta2 ** self.step)) + self.eps)) * m/(1 - self.beta1 ** self.step)\\\n","                        for w, m, g in zip(self.weights, self.m_w, self.g_w)]\n","\n","        self.m_b = [self.beta1 * m + (1 - self.beta1) * (nw/len(x_batch))\\\n","                  for m, nw in zip(self.m_b, nabla_b)]\n","        self.g_b = [self.beta2 * g + (1 - self.beta2) * (nw/len(x_batch))**2\\\n","                  for g, nw in zip(self.g_b, nabla_b)]\n","        self.g_b_hat = [np.maximum(g_hat, g) for g_hat, g in zip(self.g_b_hat, self.g_b)]\n","        self.biases = [w - (eta / (np.sqrt(g/(1 - self.beta2 ** self.step)) + self.eps)) * m/(1 - self.beta1 ** self.step)\\\n","                        for w, m, g in zip(self.biases, self.m_b, self.g_b)]\n","        self.step += 1\n","\n","network9 = Network_AMSGrad([784,100,30,10], act_name='sigmoid', beta1=0.9, beta2=0.99, eps=1e-8)\n","network9.SGD((x_train, y_train), epochs=150, mini_batch_size=100, eta=0.05,\n","            test_data=(x_test, y_test), step=2)"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Accuracy: 0.9216\n","Epoch: 2, Accuracy: 0.9351\n","Epoch: 4, Accuracy: 0.9411\n","Epoch: 6, Accuracy: 0.9392\n","Epoch: 8, Accuracy: 0.9453\n","Epoch: 10, Accuracy: 0.9486\n","Epoch: 12, Accuracy: 0.949\n","Epoch: 14, Accuracy: 0.9437\n","Epoch: 16, Accuracy: 0.9498\n","Epoch: 18, Accuracy: 0.9502\n","Epoch: 20, Accuracy: 0.9497\n","Epoch: 22, Accuracy: 0.9533\n","Epoch: 24, Accuracy: 0.9538\n","Epoch: 26, Accuracy: 0.9505\n","Epoch: 28, Accuracy: 0.9529\n","Epoch: 30, Accuracy: 0.9488\n","Epoch: 32, Accuracy: 0.9556\n","Epoch: 34, Accuracy: 0.9596\n","Epoch: 36, Accuracy: 0.9547\n","Epoch: 38, Accuracy: 0.9544\n","Epoch: 40, Accuracy: 0.9529\n","Epoch: 42, Accuracy: 0.956\n","Epoch: 44, Accuracy: 0.9581\n","Epoch: 46, Accuracy: 0.9559\n","Epoch: 48, Accuracy: 0.9599\n","Epoch: 50, Accuracy: 0.9566\n","Epoch: 52, Accuracy: 0.9558\n","Epoch: 54, Accuracy: 0.9551\n","Epoch: 56, Accuracy: 0.96\n","Epoch: 58, Accuracy: 0.9557\n","Epoch: 60, Accuracy: 0.9568\n","Epoch: 62, Accuracy: 0.9606\n","Epoch: 64, Accuracy: 0.9594\n","Epoch: 66, Accuracy: 0.9601\n","Epoch: 68, Accuracy: 0.9554\n","Epoch: 70, Accuracy: 0.9583\n","Epoch: 72, Accuracy: 0.9614\n","Epoch: 74, Accuracy: 0.9591\n","Epoch: 76, Accuracy: 0.9558\n","Epoch: 78, Accuracy: 0.9568\n","Epoch: 80, Accuracy: 0.9596\n","Epoch: 82, Accuracy: 0.9587\n","Epoch: 84, Accuracy: 0.9592\n","Epoch: 86, Accuracy: 0.9585\n","Epoch: 88, Accuracy: 0.9591\n","Epoch: 90, Accuracy: 0.9626\n","Epoch: 92, Accuracy: 0.961\n","Epoch: 94, Accuracy: 0.9591\n","Epoch: 96, Accuracy: 0.9591\n","Epoch: 98, Accuracy: 0.9606\n","Epoch: 100, Accuracy: 0.9616\n","Epoch: 102, Accuracy: 0.9636\n","Epoch: 104, Accuracy: 0.9613\n","Epoch: 106, Accuracy: 0.9607\n","Epoch: 108, Accuracy: 0.9632\n","Epoch: 110, Accuracy: 0.9607\n","Epoch: 112, Accuracy: 0.9601\n","Epoch: 114, Accuracy: 0.9617\n","Epoch: 116, Accuracy: 0.9619\n","Epoch: 118, Accuracy: 0.9615\n","Epoch: 120, Accuracy: 0.9571\n","Epoch: 122, Accuracy: 0.9627\n","Epoch: 124, Accuracy: 0.9607\n","Epoch: 126, Accuracy: 0.9618\n","Epoch: 128, Accuracy: 0.9614\n","Epoch: 130, Accuracy: 0.9607\n","Epoch: 132, Accuracy: 0.9617\n","Epoch: 134, Accuracy: 0.9624\n","Epoch: 136, Accuracy: 0.9641\n","Epoch: 138, Accuracy: 0.9622\n","Epoch: 140, Accuracy: 0.9624\n","Epoch: 142, Accuracy: 0.9653\n","Epoch: 144, Accuracy: 0.9626\n","Epoch: 146, Accuracy: 0.9602\n","Epoch: 148, Accuracy: 0.9638\n"]}]},{"cell_type":"markdown","metadata":{"id":"0gY5UfFyCxnm"},"source":["Gradient Noise"]},{"cell_type":"code","metadata":{"id":"uMkGGh9EC0CC"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o5rZatpV-1hu"},"source":["Dropout"]},{"cell_type":"code","metadata":{"id":"XcXoC7sF-23U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638748650946,"user_tz":-60,"elapsed":125119,"user":{"displayName":"Bartłomiej Krzepkowski","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14471650214675903305"}},"outputId":"76f88aef-d0f3-4950-d2b1-592e1a3bdfd1"},"source":["class Network(Network_):\n","  def __init__(self, sizes, act_name, p_drop):\n","    super(Network, self).__init__(sizes, act_name)\n","    self.drop_mask = np.random.binomial\n","    self.b = [np.zeros_like(b) for b in self.biases]\n","    self.p_drop = p_drop\n","    self.multiplier = 1. / (1. - self.p_drop)\n","\n","  def backprop(self, x_batch, y_batch):\n","        # For a single input (x,y) return a tuple of lists.\n","        # First contains gradients over biases, second over weights.\n","        \n","        fs = [x_batch]\n","        deriv_fs = []\n","        for w,b in zip(self.weights[:-1], self.biases[:-1]):\n","          h = w @ fs[-1] + b\n","          f = relu(h) if self.act_name == 'relu' else sigmoid(h)\n","          deriv_fs.append((h>0).astype(int) \\\n","                          if self.act_name == 'relu' else f*(1-f))\n","          mask = np.random.rand(*f.shape) > self.p_drop\n","          f = f * mask * self.multiplier\n","          fs.append(f)\n","\n","        h = np.dot(self.weights[-1], f) + self.biases[-1]\n","        # Now go backward from the final cost applying backpropagation\n","        # dLdf = dLdh\n","        dLdh = self.cost_derivative(h, y_batch)\n","        dLdhs = [dLdh.copy()]\n","        for w, deriv_f in reversed(list(zip(self.weights[1:], deriv_fs))):\n","          dLdf = w.T @ dLdh\n","          dLdh = dLdf * deriv_f\n","          dLdhs.append(dLdh)\n","          \n","        delta_nabla_w = [dLdh @ f.T for dLdh, f in zip(reversed(dLdhs),fs)] \n","        delta_nabla_b = [dLdh.sum(axis=1)[:, np.newaxis] \n","                         for dLdh in reversed(dLdhs)]\n","\n","        return (delta_nabla_b, delta_nabla_w)\n","\n","network1 = Network([784, 64, 10], act_name='relu', p_drop=0.2)\n","network1.SGD((x_train, y_train), epochs=100, mini_batch_size=100, eta=0.5,\n","            test_data=(x_test, y_test), step=2)"],"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Accuracy: 0.9488\n","Epoch: 2, Accuracy: 0.95\n","Epoch: 4, Accuracy: 0.9611\n","Epoch: 6, Accuracy: 0.9623\n","Epoch: 8, Accuracy: 0.9679\n","Epoch: 10, Accuracy: 0.9682\n","Epoch: 12, Accuracy: 0.971\n","Epoch: 14, Accuracy: 0.9633\n","Epoch: 16, Accuracy: 0.9686\n","Epoch: 18, Accuracy: 0.9693\n","Epoch: 20, Accuracy: 0.9691\n","Epoch: 22, Accuracy: 0.9548\n","Epoch: 24, Accuracy: 0.9711\n","Epoch: 26, Accuracy: 0.9655\n","Epoch: 28, Accuracy: 0.9722\n","Epoch: 30, Accuracy: 0.9658\n","Epoch: 32, Accuracy: 0.9732\n","Epoch: 34, Accuracy: 0.9714\n","Epoch: 36, Accuracy: 0.9732\n","Epoch: 38, Accuracy: 0.9709\n","Epoch: 40, Accuracy: 0.9672\n","Epoch: 42, Accuracy: 0.9711\n","Epoch: 44, Accuracy: 0.9655\n","Epoch: 46, Accuracy: 0.9678\n","Epoch: 48, Accuracy: 0.9703\n","Epoch: 50, Accuracy: 0.9668\n","Epoch: 52, Accuracy: 0.9663\n","Epoch: 54, Accuracy: 0.9698\n","Epoch: 56, Accuracy: 0.9689\n","Epoch: 58, Accuracy: 0.9741\n","Epoch: 60, Accuracy: 0.9681\n","Epoch: 62, Accuracy: 0.9754\n","Epoch: 64, Accuracy: 0.9681\n","Epoch: 66, Accuracy: 0.9635\n","Epoch: 68, Accuracy: 0.9719\n","Epoch: 70, Accuracy: 0.9706\n","Epoch: 72, Accuracy: 0.9721\n","Epoch: 74, Accuracy: 0.9668\n","Epoch: 76, Accuracy: 0.9634\n","Epoch: 78, Accuracy: 0.9725\n","Epoch: 80, Accuracy: 0.9726\n","Epoch: 82, Accuracy: 0.9683\n","Epoch: 84, Accuracy: 0.9717\n","Epoch: 86, Accuracy: 0.9631\n","Epoch: 88, Accuracy: 0.9688\n","Epoch: 90, Accuracy: 0.9642\n","Epoch: 92, Accuracy: 0.97\n","Epoch: 94, Accuracy: 0.967\n","Epoch: 96, Accuracy: 0.9754\n","Epoch: 98, Accuracy: 0.9741\n"]}]},{"cell_type":"markdown","metadata":{"id":"-lOi34A51H9U"},"source":["BatchNormalization"]},{"cell_type":"code","metadata":{"id":"FH1Tx_8N1PIU","colab":{"base_uri":"https://localhost:8080/","height":502},"executionInfo":{"status":"error","timestamp":1638833642299,"user_tz":-60,"elapsed":39395,"user":{"displayName":"Bartłomiej Krzepkowski","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14471650214675903305"}},"outputId":"f50fa8e7-ec5b-46f3-ddd6-a1c315d93050"},"source":["class Network(Network_):\n","  def __init__(self, sizes, act_name, bn_eps=1e-5, bn_momentum=0.1):\n","    super(Network, self).__init__(sizes, act_name)\n","    self.bn_eps = bn_eps\n","    self.bn_m = bn_momentum\n","    self.gamma = [np.zeros((dim, 1)) for dim in sizes[1:]]\n","    self.beta = [np.ones((dim, 1)) for dim in sizes[1:]]\n","    self.mu = [np.zeros((dim, 1)) for dim in sizes[1:]]\n","    self.sigma2 = [np.ones((dim, 1)) for dim in sizes[1:]]\n","\n","  def bn_train(self, x, i):\n","    mean = x.mean(axis=1)[:,np.newaxis]\n","    var = x.var(axis=1)[:,np.newaxis]\n","    self.mu[i] = (1 - self.bn_m) * self.mu[i] + self.bn_m * mean\n","    self.sigma2[i] = (1 - self.bn_m) * self.sigma2[i] + self.bn_m * var\n","    t = 1. / np.sqrt(var + self.bn_eps)\n","    z = (x - mean) * t\n","    return z, t\n","\n","\n","  def bn_test(self, x, i):\n","    z = (x - self.mu[i]) / np.sqrt(self.sigma2[i] + self.bn_eps)\n","    return z\n","\n","\n","  def feedforward(self, a):\n","        # Run the network on a batch\n","        for i, (w, b, gamma, beta) in enumerate(zip(self.weights[:-1], self.biases[:-1], self.gamma[:-1], self.beta[:-1])):\n","          h = np.dot(w, a) #+ b\n","          h = gamma * self.bn_test(h, i) + beta\n","          a = relu(h) if self.act_name == 'relu' else sigmoid(h)\n","        h = np.dot(self.weights[-1], a) + self.biases[-1]\n","        return h\n","\n","  def update_mini_batch(self, x_batch, y_batch, eta):\n","        # Update networks weights and biases by applying a single step\n","        # of gradient descent using backpropagation to compute the gradient.\n","        # The gradient is computed for a mini_batch.\n","        # eta is the learning rate\n","        nabla_b, nabla_w, nabla_gamma, nabla_beta = self.backprop(x_batch.T, y_batch.T)\n","        self.weights = [w-(eta/len(x_batch))*nw \n","                        for w, nw in zip(self.weights, nabla_w)]\n","        self.biases = [b-(eta/len(x_batch))*nb \n","                       for b, nb in zip(self.biases, nabla_b)]\n","        self.mu = [mu-(eta/len(x_batch))*beta \n","                        for mu, beta in zip(self.mu, nabla_beta)]\n","        self.sigma2 = [sigma2-(eta/len(x_batch))*gamma \n","                        for sigma2, gamma in zip(self.sigma2, nabla_gamma)]\n","\n","\n","  def backprop(self, x_batch, y_batch):\n","        # For a single input (x,y) return a tuple of lists.\n","        # First contains gradients over biases, second over weights.\n","        \n","        fs = [x_batch]\n","        deriv_fs = []\n","        normalized_h = []\n","        ts = []\n","        for i, (w, b, gamma, beta) in enumerate(zip(self.weights[:-1], self.biases[:-1], self.gamma[:-1], self.beta[:-1])):\n","          h = w @ fs[-1]# + b\n","          ########################\n","          h, t = self.bn_train(h, i)\n","          normalized_h.append(h)\n","          ts.append(t)\n","          h = gamma * h + beta\n","          ########################\n","          f = relu(h) if self.act_name == 'relu' else sigmoid(h)\n","          fs.append(f)\n","          deriv_fs.append((f>0).astype(int) \\\n","                          if self.act_name == 'relu' else f*(1-f))\n","\n","        h = np.dot(self.weights[-1], f) + self.biases[-1]\n","        # bn = self.gamma[-1] * self.bn_train(h, -1) + self.beta[-1]\n","        # Now go backward from the final cost applying backpropagation\n","        # dLdf = dLdh\n","        dLdh = self.cost_derivative(h, y_batch)\n","        dLdhs_bn = []\n","        dLdhs = [dLdh.copy()]\n","        m = x_batch.shape[1]\n","        for w, deriv_f, gamma, t, h_hat in reversed(list(zip(self.weights[1:],deriv_fs, self.gamma[:-1], ts, normalized_h))):\n","          dLdf = w.T @ dLdh\n","          dLdh = dLdf * deriv_f\n","          dLdhs_bn.append(dLdh)\n","          ########################\n","          dLdsigma2 = (dLdh * h_hat).sum(axis=1)[:, np.newaxis]\n","          dLdmu = dLdh.sum(axis=1)[:, np.newaxis]\n","          dLdhh = m#((m-1)-h_hat**2)\n","          dLdh = gamma * t / m * (dLdhh * dLdh - dLdsigma2 * h_hat - dLdmu) #((m-1)-x_hat**2)\n","          ########################\n","          dLdhs.append(dLdh)\n","          \n","        delta_nabla_w = [dLdh @ f.T for dLdh, f in zip(reversed(dLdhs),fs)] \n","        delta_nabla_b = [dLdh.sum(axis=1)[:, np.newaxis] \n","                         for dLdh in reversed(dLdhs)]\n","        delta_nabla_gamma = [(dLdh * h_norm).sum(axis=1)[:, np.newaxis] for dLdh, h_norm in zip(reversed(dLdhs_bn), normalized_h)] \n","        delta_nabla_beta = [dLdh.sum(axis=1)[:, np.newaxis] \n","                         for dLdh in reversed(dLdhs_bn)] \n","\n","        return (delta_nabla_b, delta_nabla_w, delta_nabla_gamma, delta_nabla_beta)\n","\n","network1 = Network([784,100,30,10], act_name='relu')\n","network1.SGD((x_train, y_train), epochs=100, mini_batch_size=100, eta=0.05,\n","            test_data=(x_test, y_test), step=2)"],"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Accuracy: 0.1009\n","Epoch: 2, Accuracy: 0.1135\n","Epoch: 4, Accuracy: 0.1028\n","Epoch: 6, Accuracy: 0.1135\n","Epoch: 8, Accuracy: 0.1135\n","Epoch: 10, Accuracy: 0.0958\n","Epoch: 12, Accuracy: 0.0982\n","Epoch: 14, Accuracy: 0.1135\n","Epoch: 16, Accuracy: 0.1009\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-81-e2eb1ab7bff9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0mnetwork1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m network1.SGD((x_train, y_train), epochs=100, mini_batch_size=100, eta=0.05,\n\u001b[0;32m--> 102\u001b[0;31m             test_data=(x_test, y_test), step=2)\n\u001b[0m","\u001b[0;32m<ipython-input-76-335264b81c49>\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(self, training_data, epochs, mini_batch_size, eta, test_data, p, step)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mx_mini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0my_mini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_mini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-81-e2eb1ab7bff9>\u001b[0m in \u001b[0;36mupdate_mini_batch\u001b[0;34m(self, x_batch, y_batch, eta)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# The gradient is computed for a mini_batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# eta is the learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mnabla_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnabla_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnabla_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnabla_beta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         self.weights = [w-(eta/len(x_batch))*nw \n\u001b[1;32m     42\u001b[0m                         for w, nw in zip(self.weights, nabla_w)]\n","\u001b[0;32m<ipython-input-81-e2eb1ab7bff9>\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(self, x_batch, y_batch)\u001b[0m\n\u001b[1;32m     89\u001b[0m           \u001b[0mdLdhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdLdh2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mdelta_nabla_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdLdh\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdLdh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdLdhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         delta_nabla_b = [dLdh.sum(axis=1)[:, np.newaxis] \n\u001b[1;32m     93\u001b[0m                          for dLdh in reversed(dLdhs)]\n","\u001b[0;32m<ipython-input-81-e2eb1ab7bff9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     89\u001b[0m           \u001b[0mdLdhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdLdh2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mdelta_nabla_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdLdh\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdLdh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdLdhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         delta_nabla_b = [dLdh.sum(axis=1)[:, np.newaxis] \n\u001b[1;32m     93\u001b[0m                          for dLdh in reversed(dLdhs)]\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"bKTiU9MH2JmT"},"source":["Inne wersje backprop"]},{"cell_type":"code","metadata":{"id":"BKBj9u_cX6-O"},"source":["       # def backprop(self, x_batch, y_batch):\n","    #     # For a single input (x,y) return a tuple of lists.\n","    #     # First contains gradients over biases, second over weights.\n","        \n","    #     # First initialize the list of gradient arrays\n","    #     delta_nabla_b = [np.zeros_like(p) for p in self.biases]\n","    #     delta_nabla_w = [np.zeros_like(p) for p in self.weights]\n","        \n","    #     # Then go forward remembering all values before and after activations\n","    #     # in two other array lists\n","    #     a = x_batch\n","    #     post_act = []\n","    #     for w, b in zip(self.weights, self.biases):\n","    #       a = sigmoid(np.dot(w, a) + b)\n","    #       post_act.append(a)\n","        \n","    #     # Now go backward from the final cost applying backpropagation\n","    #     ph2 = np.multiply((post_act[1] - y_batch), np.multiply(post_act[1], (1 - post_act[1])))\n","    #     delta_nabla_b[1] += np.sum(ph2,axis=1).reshape(ph2.shape[0],1)#ph2.sum(axis=1)[:, np.newaxis]\n","    #     delta_nabla_w[1] += np.matmul(ph2, post_act[0].T) #+ 0.0001 * x_batch.shape[1] * self.weights[1]\n","        \n","    #     ph1 = np.multiply(np.matmul(self.weights[1].T, ph2), np.multiply(post_act[0], (1 - post_act[0])))\n","    #     delta_nabla_b[0] += np.sum(ph1,axis=1).reshape(ph1.shape[0],1)#ph1.sum(axis=1)[:, np.newaxis]\n","    #     delta_nabla_w[0] += np.matmul(ph1, x_batch.T) #+ 0.0001 * x_batch.shape[1] * self.weights[0]\n","\n","    #     return (delta_nabla_b, delta_nabla_w)"],"execution_count":null,"outputs":[]}]}